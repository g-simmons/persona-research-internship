{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook can be used to learn how to successfull run TextAttack. \n",
    "A library dedicated to adversarial attacks, data augmentation, and model training in NLP.\n",
    "\n",
    "The GitHub can be found here: https://github.com/QData/TextAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"NOTE: Lines in this cell reload every file in the current environment\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at j-hartmann/sentiment-roberta-large-english-3-classes were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import textattack\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "class CustomHuggingFaceSentimentAnalysisPipelineWrapper(ModelWrapper):\n",
    "    \"\"\"Transformers sentiment analysis pipeline returns a list of responses,\n",
    "    like\n",
    "        [{'label': 'POSITIVE', 'score': 0.8}, {'label': 'NEUTRAL', 'score': 0.15}, {'label': 'NEGATIVE', 'score': 0.05}]\n",
    "    The Following code will make the output look more like this\n",
    "        [[0.875, 0.125]\n",
    "\n",
    "    In this example we are adding each half of the score from 'NEUTRAl' to the 'POSTIVE' and 'NEGATIVE' scores.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, text_inputs):\n",
    "        # print(\"TEXT INPUTS: \", text_inputs)\n",
    "        raw_outputs = self.model(text_inputs)\n",
    "        outputs = []\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        neutral_score = 0\n",
    "        for output in raw_outputs:\n",
    "            # print(output , type(output))\n",
    "            for item in output:\n",
    "                if item[\"label\"] == \"positive\":\n",
    "                    pos_score = item[\"score\"]\n",
    "                if item[\"label\"] == \"negative\":\n",
    "                    neg_score = item[\"score\"]\n",
    "                if item[\"label\"] == \"neutral\":\n",
    "                    neutral_score = item[\"score\"]\n",
    "\n",
    "            total_score = pos_score + neutral_score + neg_score\n",
    "            pos_score = (pos_score + (neutral_score / 2) ) / total_score\n",
    "            neg_score = (neg_score + (neutral_score / 2) ) / total_score\n",
    "            # print(\"NEG SENTIMENT: \", neg_score,\" POS SENTIMENT: \",pos_score)\n",
    "\n",
    "            \n",
    "\n",
    "            \"NOTE: [groud_truth_output_0, ground_truth_output_1]\"\n",
    "            \n",
    "            outputs.append([neg_score, pos_score])\n",
    "\n",
    "        return np.array(outputs)\n",
    "    \n",
    "\n",
    "#Create classifer object.\n",
    "    #task: Type of model\n",
    "    #model: Model pulled from https://huggingface.co \n",
    "        #Current example is pulling from https://huggingface.co/j-hartmann/sentiment-roberta-large-english-3-classes\n",
    "    #top_k: Number of predictions to return. Code crashes if not set to None...\n",
    "    \n",
    "classifier = pipeline(task=\"sentiment-analysis\", model=\"j-hartmann/sentiment-roberta-large-english-3-classes\", top_k=None)\n",
    "\n",
    "#Creating the model wrapper:\n",
    "model_wrapper = CustomHuggingFaceSentimentAnalysisPipelineWrapper(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack import Attack\n",
    "from textattack.constraints.pre_transformation import StopwordModification\n",
    "from textattack.goal_functions import UntargetedClassification\n",
    "from textattack.search_methods import GreedyWordSwapWIR\n",
    "from textattack.attack_recipes import AttackRecipe\n",
    "from textattack.transformations import WordSwapEmbedding\n",
    "\n",
    "\n",
    "\n",
    "#This is the code responsible for generating attacks. This Recipee object is loaded into the Attacker object later on...\n",
    "    #We can tweek transformation methods, add constraints,  \n",
    "class CustomRecipe(AttackRecipe):\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def build(model_wrapper):\n",
    "        \n",
    "        #transformation: What we would like to do to our text\n",
    "        #constrains: constraints to prevent transformations to happen to certain parts of the text\n",
    "        #goal_function: \n",
    "            #An untargeted attack on classification models which attempts to minimize the score of the correct label until it is no longer the predicted label.\n",
    "            #UntargetedClassification(model_wrapper, target_max_score)\n",
    "            #target_max_score is what we would like our initial ouput to reduce to. \n",
    "            #Example: Inital Score 0.9 Positive -> 0.001 Positive (effectively 0.999 Negative)\n",
    "        #search_method: How we sort our results.\n",
    "            #In the example of sentiment analysis, we are sorting sentiment scores based off of text perturbations\n",
    "        \n",
    "        goal_function = UntargetedClassification(model_wrapper, target_max_score=0.001)\n",
    "        transformation = WordSwapEmbedding(max_candidates=200)\n",
    "        constraints = [StopwordModification()]\n",
    "        search_method = GreedyWordSwapWIR(\"weighted-saliency\")\n",
    "        \n",
    "        return Attack(goal_function, constraints, transformation, search_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'transformers.pipelines.text_classification.TextClassificationPipeline'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "textattack: Attempting to attack 14 samples when only 1 are available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  weighted-saliency\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  200\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brody Print from greed_word_swap_wir.py: initial results  GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a positive sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0017831529842378124\n",
      ")\n",
      "Brody Print from greed_word_swap_wir.py: performing_search\n",
      "RESULTS [GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9973213427820377\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a permissive sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.6771229707337312\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a lucrative sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5441315127527873\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a charitable sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5244747364268443\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a valid sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5065978674099969\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a corrective sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5043492147457603\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a meaningful sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5019993509887257\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a aggressively sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5003304880166113\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a vigorously sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49980401775887184\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a presentable sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4997443455804781\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promote sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49973875527616485\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a enabling sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49973056226052137\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a help sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4997211705338259\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a preferably sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4997203238134178\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a foster sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49969288771313924\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a actionable sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4996842431558687\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a active sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49965934787615407\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a hopeful sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4996315014120769\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a helps sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49962764882207755\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a actively sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4995922891588257\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a dynamics sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49958149645105754\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a supporting sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49956669315771784\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a fostered sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4995323933945297\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a fostering sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49952511194881166\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a proactive sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4995090196755101\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a supported sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49945434492003304\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoted sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4994415629963319\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a helping sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4993650693962134\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a preferred sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4992439855825551\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a support sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4989627573713583\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a dynamic sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4986046853872702\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a prefers sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49851401841414555\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a favor sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4984956267173035\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a favour sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4969089051546337\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a preferable sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4962865643468919\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a preferential sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4962311622338027\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a sociable sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4957805689828785\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a profitable sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4923504404723644\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a positives sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4911266464639744\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a useful sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.47344704463839304\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a sympathetic sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.3833631666993623\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a privileged sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.32987703034402305\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a opportune sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.23067196365151443\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a helpful sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.14602779546778455\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a conducive sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.1450510032986747\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a vigorous sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.13575968288793394\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a effective sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.1033480625919666\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a fertile sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.08115790456915739\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a favoured sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.07402483396188086\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a propitious sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.05526061409932226\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a advisable sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.05495948880790136\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a advantageous sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.041350552688029785\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a reassuring sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.03490794416959897\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a affirmative sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.018912248610666982\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a energetic sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.018260168457323922\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promising sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.013884690667789523\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a fecund sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.010806834677457022\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a benevolent sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0046584950078518705\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a ripe sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.004547991230102966\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a salubrious sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.004473899095261302\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a favourable sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.002019773089143806\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a beneficial sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.00199626879896575\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a productive sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.001994283906378347\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a constructive sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0016638169661893354\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a favored sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0013699855925379811\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a handy sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0011514288504795855\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a supportive sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0011194871375822535\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a efficacious sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0009879132846102312\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a satisfactory sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0008641182165853856\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a worthwhile sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0008586752171844125\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a upbeat sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0008364126631740243\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a positively sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0006691973256041095\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a favorably sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0006531358709908064\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a congenial sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0005653629864630361\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a encouraging sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0004944638036116222\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a decent sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0004872079278692709\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a favorable sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.00047958161028971436\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a fruitful sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.00040578101977462033\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a successful sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.00039036009491533186\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a good sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.00038047618727032884\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a comforting sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.000371375279627717\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a fortunate sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0003706853609516392\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a favourably sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.00036695364407213216\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a welcome sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0003294407354386131\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a welcoming sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0003282606803948207\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a healthful sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0003236605731413711\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a agreeable sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0003233572304294219\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a favore sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0003097826541579307\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a enthusiastically sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.00028340024987083545\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a favouring sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0002827875461373086\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a pleasant sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0002827042800754853\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a favours sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0002824288457912161\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a auspicious sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.00028232504451630724\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a satisfying sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.00027792785177260804\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a heartening sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0002739484005261916\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a pleasing sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0002693216768095974\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a rewarding sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.00026594080731345837\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a pleasurable sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.00026364986194815643\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a gratifying sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.00026157058346931716\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a vibrant sentence\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.0002543272191565249\n",
      ")]\n",
      "Conditional check:  False\n",
      "cur_result.goal_status type:  <class 'int'> Value:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:   7%|â–‹         | 1/14 [00:55<12:06, 55.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS [GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting disapproving\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9995011349327556\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting denounces\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994934547379878\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting penalized\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994873378224434\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting reprieved\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.999484996650851\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting denounced\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994825719882843\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting denounce\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994802866333449\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting denouncing\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994742985300613\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting penalize\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994742726915264\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting regretted\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994718838821446\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting condemned\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994662740544711\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting condemning\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994661114368794\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting regret\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994645412946871\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting condemn\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994606216804159\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting punished\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994582023532119\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting doomed\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994564777063324\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting spite\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994562996887064\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting condemnation\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994561628869818\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting punitive\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994478198798616\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting condemns\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994442997397953\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting punishing\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994406356161961\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting censure\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994395535268417\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting rebuke\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994387576677768\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting blame\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994354099418468\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting sadness\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994353322758373\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting excommunication\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994347859041921\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting judgement\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994278617095714\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting heartbreak\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994274910579664\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting heartache\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994235952596798\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting remorse\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994235219191845\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting pity\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994216883578982\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting judgment\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994212953931007\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting sorrows\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994200278617504\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting deplore\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994197936846819\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting reprimand\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9994141506144731\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting sorrow\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9993998469302339\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting penal\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9993984833140718\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting grief\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9993932303212717\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting culpability\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9993924538149687\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting guilt\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9993743709489276\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting death\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9993733539472164\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting damnation\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9993730146612698\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting punish\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9993484518667499\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting penalties\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9993402456153042\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting fines\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9993159414543282\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting convicted\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9993152409049688\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting stoning\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9993044242182593\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting judgments\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9993001610576704\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting penalty\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9992880934565007\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting punishments\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.999281295060356\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting sanctions\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9992708704611144\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting punishes\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9992458666428861\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting punishment\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9992423317510969\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting ruling\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9992311563977577\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting fined\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9992242374822164\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting convicting\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9992156262423433\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting convict\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9991615685220685\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting bereavement\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9991368915459936\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting sentenced\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9990329237968778\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting verdict\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9990305697727124\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting chastisement\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.999019309003142\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting sentencing\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.998731846023336\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting decision\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9985911830455177\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting decisions\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9985610918892293\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting pena\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9983429119576616\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting pardon\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9981878728725729\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting amounting\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9981639257738032\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting sanction\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9978473197841534\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting beliefs\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.997782477316152\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting amnesty\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9976266736755648\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting convicts\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.995728832872566\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting pardoned\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9956854229836644\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting convictions\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9914042830939409\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting term\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9891932596047376\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting judgements\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.986799887303288\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting contrition\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9708068469143956\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting rulings\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9632302993625316\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting dom\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.9296744368078919\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting repent\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5316479763375153\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting verdicts\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5277982704870219\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting stoppage\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5208727672185404\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting phrase\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.504210393977548\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting pronouncing\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5040271808007397\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting repentance\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.501635537112866\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting judging\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5010231104794762\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting conviction\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5005713717498422\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting priors\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5005636222032079\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting sentences\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5004498473094907\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting forgave\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5002718453133814\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting meted\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 0\n",
      "  (score): 0.5002364572626904\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting worth\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49992337741350257\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting phrases\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49991091608810323\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting adjudged\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49989796438939227\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting prayer\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49958706469429237\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting prayers\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.49953145392519194\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting clemency\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4995258218565769\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting forgive\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4994443712123523\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting stops\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4994420136873343\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting discernment\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4993291660649124\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting mercy\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.4659060662274783\n",
      "), GoalFunctionResult( \n",
      "  (goal_function_result_type): Classification\n",
      "  (attacked_text): This is a promoting compassion\n",
      "  (ground_truth_output): 1\n",
      "  (model_output): 1\n",
      "  (score): 0.44961416721343994\n",
      ")]\n",
      "Conditional check:  True\n",
      "cur_result.goal_status type:  <class 'int'> Value:  0\n",
      "SELF MESSAGE: IT WAS A SUCCESS\n",
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[1 (100%)]] --> [[0 (100%)]]\n",
      "\n",
      "This is a [[positive]] [[sentence]]\n",
      "\n",
      "This is a [[promoting]] [[disapproving]]\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 1      |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "| Average perturbed word %:     | 40.0%  |\n",
      "| Average num. words per input: | 5.0    |\n",
      "| Avg num queries:              | 504.0  |\n",
      "+-------------------------------+--------+\n",
      "Results from attack.py:  [<textattack.attack_results.successful_attack_result.SuccessfulAttackResult object at 0x000001F0CC330D50>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from textattack import AttackArgs, Attacker\n",
    "from textattack.datasets import Dataset\n",
    "\n",
    "\n",
    "#Creating a recipee to use use for the Attacker object\n",
    "recipe = CustomRecipe.build(model_wrapper)\n",
    "#Identifying the language for the recipe\n",
    "recipe.transformation.language = \"eng\"\n",
    "\n",
    "#dataset: obj: Dataset() takes in list: of tuples. \n",
    "    #tuples: (\"example string\", ground_truth_output: int)\n",
    "dataset = Dataset([(\"This is a positive sentence\", 1)])\n",
    "\n",
    "attack_args = AttackArgs(\n",
    "    #Notable Arguments: \n",
    "        #num_examples: int Number of examples to attack\n",
    "        #num_successful_exmaples: int Number of success examples that have been attacked. Overrides num_examples if set.\n",
    "        #checkpoint_interval: int Save progress after number of attacks\n",
    "    num_successful_examples=14,\n",
    "    )\n",
    "#Create attacker object.\n",
    "attacker = Attacker(recipe, dataset, attack_args,)\n",
    "#Attacks the dataset\n",
    "testresults = attacker.attack_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Logging to CSV at path results.csv\n",
      "C:\\Users\\14158\\AppData\\Local\\Temp\\ipykernel_49920\\531151280.py:15: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>perturbed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a <font color = green>positive</font> <font color = green>sentence</font></td>\n",
       "      <td>This is a <font color = red>promoting</font> <font color = red>disapproving</font></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textattack.loggers import CSVLogger\n",
    "from textattack.attack_results import FailedAttackResult, SuccessfulAttackResult\n",
    "\n",
    "#Prints outputs of successful adversial attacks\n",
    "\n",
    "pd.options.display.max_colwidth = (\n",
    "    480  # increase colum width so we can actually read the examples\n",
    ")\n",
    "\n",
    "logger = CSVLogger(color_method=\"html\")\n",
    "for result in testresults:\n",
    "    if isinstance(result, SuccessfulAttackResult):\n",
    "        logger.log_attack_result(result)\n",
    "from IPython.core.display import display, HTML\n",
    "df_results = pd.DataFrame.from_records(logger.row_list)\n",
    "# print(df_results[[\"original_text\", \"perturbed_text\"]])\n",
    "display(HTML(df_results[[\"original_text\", \"perturbed_text\"]].to_html(escape=False)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
