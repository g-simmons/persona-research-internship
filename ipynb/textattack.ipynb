{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textattack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "# class ModelWrapper(ABC):\n",
    "#     \"\"\"A model wrapper queries a model with a list of text inputs.\n",
    "\n",
    "#     Classification-based models return a list of lists, where each sublist\n",
    "#     represents the model's scores for a given input.\n",
    "\n",
    "#     Text-to-text models return a list of strings, where each string is the\n",
    "#     output – like a translation or summarization – for a given input.\n",
    "#     \"\"\"\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def __call__(self, text_input_list, **kwargs):\n",
    "#         raise NotImplementedError()\n",
    "\n",
    "#     def get_grad(self, text_input):\n",
    "#         \"\"\"Get gradient of loss with respect to input tokens.\"\"\"\n",
    "#         raise NotImplementedError()\n",
    "\n",
    "#     def _tokenize(self, inputs):\n",
    "#         \"\"\"Helper method for `tokenize`\"\"\"\n",
    "#         raise NotImplementedError()\n",
    "\n",
    "#     def tokenize(self, inputs, strip_prefix=False):\n",
    "#         \"\"\"Helper method that tokenizes input strings\n",
    "#         Args:\n",
    "#             inputs (list[str]): list of input strings\n",
    "#             strip_prefix (bool): If `True`, we strip auxiliary characters added to tokens as prefixes (e.g. \"##\" for BERT, \"Ġ\" for RoBERTa)\n",
    "#         Returns:\n",
    "#             tokens (list[list[str]]): List of list of tokens as strings\n",
    "#         \"\"\"\n",
    "#         tokens = self._tokenize(inputs)\n",
    "#         if strip_prefix:\n",
    "#             # `aux_chars` are known auxiliary characters that are added to tokens\n",
    "#             strip_chars = [\"##\", \"Ġ\", \"__\"]\n",
    "#             # TODO: Find a better way to identify prefixes. These depend on the model, so cannot be resolved in ModelWrapper.\n",
    "\n",
    "#             def strip(s, chars):\n",
    "#                 for c in chars:\n",
    "#                     s = s.replace(c, \"\")\n",
    "#                 return s\n",
    "\n",
    "#             tokens = [[strip(t, strip_chars) for t in x] for x in tokens]\n",
    "\n",
    "#         return tokens\n",
    "\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "\n",
    "class PassthroughModelWrapper(ModelWrapper):\n",
    "    def __call__(self, text_input_list, **kwargs):\n",
    "        return [1.0 if \"mythic\" in text_input else 0.0 for text_input in text_input_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textattack\n",
    "from textattack.goal_function_results import GoalFunctionResult\n",
    "class MyClassificationGoalFunctionResult(GoalFunctionResult):\n",
    "    \"\"\"Represents the result of a classification goal function.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        attacked_text,\n",
    "        raw_output,\n",
    "        output,\n",
    "        goal_status,\n",
    "        score,\n",
    "        num_queries,\n",
    "        ground_truth_output,\n",
    "    ):\n",
    "\n",
    "        super().__init__(\n",
    "            attacked_text,\n",
    "            raw_output,\n",
    "            output,\n",
    "            goal_status,\n",
    "            score,\n",
    "            num_queries,\n",
    "            ground_truth_output,\n",
    "            goal_function_result_type=\"Classification\",\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def _processed_output(self):\n",
    "        \"\"\"Takes a model output (like `1`) and returns the class labeled output\n",
    "        (like `positive`), if possible.\n",
    "\n",
    "        Also returns the associated color.\n",
    "        \"\"\"\n",
    "        output_label = self.raw_output\n",
    "        if self.attacked_text.attack_attrs.get(\"label_names\") is not None:\n",
    "            output = self.attacked_text.attack_attrs[\"label_names\"][self.output]\n",
    "            output = textattack.shared.utils.process_label_name(output)\n",
    "            color = textattack.shared.utils.color_from_output(output, output_label)\n",
    "            return output, color\n",
    "        else:\n",
    "            color = textattack.shared.utils.color_from_label(output_label)\n",
    "            return output_label, color\n",
    "\n",
    "    def get_text_color_input(self):\n",
    "        \"\"\"A string representing the color this result's changed portion should\n",
    "        be if it represents the original input.\"\"\"\n",
    "        _, color = self._processed_output\n",
    "        return color\n",
    "\n",
    "    def get_text_color_perturbed(self):\n",
    "        \"\"\"A string representing the color this result's changed portion should\n",
    "        be if it represents the perturbed input.\"\"\"\n",
    "        _, color = self._processed_output\n",
    "        return color\n",
    "\n",
    "    def get_colored_output(self, color_method=None):\n",
    "        \"\"\"Returns a string representation of this result's output, colored\n",
    "        according to `color_method`.\"\"\"\n",
    "        return self.raw_output\n",
    "        # output_label = self.raw_output.argmax()\n",
    "        # confidence_score = self.raw_output[output_label]\n",
    "        # if isinstance(confidence_score, torch.Tensor):\n",
    "        #     confidence_score = confidence_score.item()\n",
    "        # output, color = self._processed_output\n",
    "        # # concatenate with label and convert confidence score to percent, like '33%'\n",
    "        # output_str = f\"{output} ({confidence_score:.0%})\"\n",
    "        # return utils.color_text(output_str, color=color, method=color_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.goal_functions import GoalFunction\n",
    "from textattack.goal_function_results import GoalFunctionResult, ClassificationGoalFunctionResult\n",
    "\n",
    "class CustomGoalFunction(GoalFunction):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_wrapper,\n",
    "        maximizable=False,\n",
    "        use_cache=False,\n",
    "        query_budget=float(\"inf\"),\n",
    "        model_batch_size=32,\n",
    "        model_cache_size=2**20,\n",
    "    ):\n",
    "        self.model = model_wrapper\n",
    "        self.maximizable = maximizable\n",
    "        self.use_cache = use_cache\n",
    "        self.query_budget = query_budget\n",
    "        self.batch_size = model_batch_size\n",
    "\n",
    "    def _is_goal_complete(self, model_output:str, attacked_text:str):\n",
    "        return True if model_output == 1.0 else False\n",
    "    \n",
    "    def _goal_function_result_type(self):\n",
    "        return MyClassificationGoalFunctionResult\n",
    "    \n",
    "    def _get_score(self, model_output, attacked_text):\n",
    "        return model_output\n",
    "    \n",
    "    def _process_model_outputs(self, inputs, outputs):\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.attack import Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.search_methods import GreedyWordSwapWIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/gabe/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from textattack.transformations import WordSwapWordNet\n",
    "attack = Attack(goal_function=CustomGoalFunction(model_wrapper=PassthroughModelWrapper()), constraints=[], transformation=WordSwapWordNet(),search_method=GreedyWordSwapWIR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/gabe/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I am mythic.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformation = WordSwapWordNet()\n",
    "\n",
    "from textattack.augmentation import Augmenter\n",
    "augmenter = Augmenter(transformation=transformation)\n",
    "\n",
    "s = 'I am fabulous.'\n",
    "augmenter.augment(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.datasets import Dataset\n",
    "dataset = Dataset([\"I am fantastic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textattack\n",
    "\n",
    "attack\n",
    "\n",
    "attack_args = textattack.AttackArgs(\n",
    "    num_examples=20,\n",
    "    log_to_csv=\"log.csv\",\n",
    "    checkpoint_interval=5,\n",
    "    checkpoint_dir=\"checkpoints\",\n",
    "    disable_stdout=True,\n",
    "    metrics={}\n",
    "\n",
    ")\n",
    "\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Logging to CSV at path log.csv\n",
      "textattack: Attempting to attack 20 samples when only 1 are available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  unk\n",
      "  )\n",
      "  (goal_function):  CustomGoalFunction\n",
      "  (transformation):  WordSwapWordNet\n",
      "  (constraints): None\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   5%|▌         | 1/20 [00:00<00:00, 52.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 0      |\n",
      "| Number of failed attacks:     | 1      |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 100.0% |\n",
      "| Attack success rate:          | 0.0%   |\n",
      "| Average perturbed word %:     | nan%   |\n",
      "| Average num. words per input: | 1.0    |\n",
      "| Avg num queries:              | 11.0   |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/gabe/opt/miniconda3/envs/mft_textgen/lib/python3.8/site-packages/textattack/metrics/attack_metrics/words_perturbed.py:83: RuntimeWarning: Mean of empty slice.\n",
      "  average_perc_words_perturbed = self.perturbed_word_percentages.mean()\n",
      "/Users/gabe/opt/miniconda3/envs/mft_textgen/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f8cb149a100>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacker.attack_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mft_textgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
